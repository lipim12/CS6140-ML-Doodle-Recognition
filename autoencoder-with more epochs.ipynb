{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau,CSVLogger\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from numpy import array\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = np.array(['aircraft carrier','airplane','alarm clock','ambulance','angel',\n",
    "                   'animal migration','ant','anvil','apple','arm','asparagus','axe',\n",
    "                   'backpack','banana','bandage','barn','baseball','baseball bat',\n",
    "                   'basket','basketball','bat','bathtub','beach','bear','beard','bed',\n",
    "                   'bee','belt','bench','bicycle','binoculars','bird','birthday cake',\n",
    "                   'blackberry','blueberry','book','boomerang','bottlecap','bowtie','bracelet',\n",
    "                   'brain','bread','bridge','broccoli','broom','bucket','bulldozer','bus','bush',\n",
    "                   'butterfly','cactus','cake','calculator','calendar','camel','camera','camouflage','campfire','candle','cannon','canoe','car','carrot','castle','cat','ceiling fan','cello','cell phone','chair',\n",
    "                   'chandelier','church','circle','clarinet','clock','cloud','coffee cup','compass','computer','cookie','cooler','couch','cow','crab','crayon','crocodile','crown','cruise ship','cup','diamond',\n",
    "                   'dishwasher','diving board','dog','dolphin','donut','door','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow','elephant','envelope','eraser','eye','eyeglasses','face','fan',\n",
    "                   'feather','fence','finger','fire hydrant','fireplace','firetruck','fish','flamingo','flashlight','flip flops','floor lamp','flower','flying saucer','foot','fork','frog','frying pan','garden',\n",
    "                   'garden hose','giraffe','goatee','golf club','grapes','grass','guitar','hamburger','hammer','hand','harp','hat','headphones','hedgehog','helicopter','helmet','hexagon','hockey puck','hockey stick',\n",
    "                   'horse','hospital','hot air balloon','hot dog','hot tub','hourglass','house','house plant','hurricane','ice cream','jacket','jail','kangaroo','key','keyboard','knee','knife','ladder','lantern','laptop',\n",
    "                   'leaf','leg','light bulb','lighter','lighthouse','lightning','line','lion','lipstick','lobster','lollipop','mailbox','map','marker','matches','megaphone','mermaid','microphone','microwave','monkey',\n",
    "                   'moon','mosquito','motorbike','mountain','mouse','moustache','mouth','mug','mushroom','nail','necklace','nose','ocean','octagon','octopus','onion','oven','owl','paintbrush','paint can','palm tree',\n",
    "                   'panda','pants','paper clip','parachute','parrot','passport','peanut','pear','peas','pencil','penguin','piano','pickup truck','picture frame','pig','pillow','pineapple','pizza','pliers','police car',\n",
    "                   'pond','pool','popsicle','postcard','potato','power outlet','purse','rabbit','raccoon','radio','rain','rainbow','rake','remote control','rhinoceros','rifle','river','roller coaster','rollerskates',\n",
    "                   'sailboat','sandwich','saw','saxophone','school bus','scissors','scorpion','screwdriver','sea turtle','see saw','shark','sheep','shoe','shorts','shovel','sink','skateboard','skull','skyscraper',\n",
    "                   'sleeping bag','smiley face','snail','snake','snorkel','snowflake','snowman','soccer ball','sock','speedboat','spider','spoon','spreadsheet','square','squiggle','squirrel','stairs','star','steak',\n",
    "                   'stereo','stethoscope','stitches','stop sign','stove','strawberry','streetlight','string bean','submarine','suitcase','sun','swan','sweater','swing set','sword','syringe','table','teapot','teddy-bear',\n",
    "                   'telephone','television','tennis racquet','tent','The Eiffel Tower','The Great Wall of China','The Mona Lisa','tiger','toaster','toe','toilet','tooth','toothbrush','toothpaste','tornado','tractor',\n",
    "                   'traffic light','train','tree','triangle','trombone','truck','trumpet','t-shirt','umbrella','underwear','van','vase','violin','washing machine','watermelon','waterslide','whale','wheel','windmill',\n",
    "                   'wine bottle','wine glass','wristwatch','yoga','zebra','zigzag'])\n",
    "# LABELS = np.array(['blackberry','blueberry','book','boomerang','bottlecap','bowtie','bracelet',\n",
    "#                    'brain','bread','bridge','broccoli','broom','bucket','bulldozer','bus','bush',\n",
    "#                    'butterfly','cactus','cake','calculator','calendar','camel','camera','camouflage','campfire','candle','cannon','canoe','car','carrot','castle','cat','ceiling fan','cello','cell phone','chair',\n",
    "#                    'chandelier','church','circle','clarinet','clock','cloud','coffee cup','compass','computer','cookie','cooler','couch','cow','crab','crayon','crocodile','crown','cruise ship','cup','diamond',\n",
    "#                    'dishwasher','diving board','dog','dolphin','donut','door','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow','elephant','envelope','eraser','eye','eyeglasses','face','fan',\n",
    "#                    'feather','fence','finger','fire hydrant','fireplace','firetruck','fish','flamingo','flashlight','flip flops','floor lamp','flower','flying saucer','foot','fork','frog','frying pan','garden',\n",
    "#                    'garden hose','giraffe','goatee','golf club','grapes','grass','guitar','hamburger','hammer','hand','harp','hat','headphones','hedgehog','helicopter','helmet','hexagon','hockey puck','hockey stick',\n",
    "#                    'horse','hospital','hot air balloon','hot dog','hot tub','hourglass','house','house plant','hurricane','ice cream','jacket','jail','kangaroo','key','keyboard','knee','knife','ladder','lantern','laptop',\n",
    "#                    'leaf','leg','light bulb','lighter','lighthouse','lightning','line','lion','lipstick','lobster','lollipop','mailbox','map','marker','matches','megaphone','mermaid','microphone','microwave','monkey',\n",
    "#                    'moon','mosquito','motorbike','mountain','mouse','moustache','mouth','mug','mushroom','nail','necklace','nose','ocean','octagon','octopus','onion','oven','owl','paintbrush','paint can','palm tree',\n",
    "#                    'panda','pants','paper clip','parachute','parrot','passport','peanut','pear','peas','pencil','penguin','piano','pickup truck','picture frame','pig','pillow','pineapple','pizza','pliers','police car',\n",
    "#                    'pond','pool','popsicle','postcard','potato','power outlet','purse','rabbit','raccoon','radio','rain','rainbow','rake','remote control','rhinoceros','rifle','river','roller coaster','rollerskates',\n",
    "#                    'sailboat','sandwich','saw','saxophone','school bus','scissors','scorpion','screwdriver','sea turtle','see saw','shark','sheep','shoe','shorts','shovel','sink','skateboard','skull','skyscraper',\n",
    "#                    'sleeping bag','smiley face','snail','snake','snorkel','snowflake','snowman','soccer ball','sock','speedboat','spider','spoon','spreadsheet','square','squiggle','squirrel','stairs','star','steak',\n",
    "#                    'stereo','stethoscope','stitches','stop sign','stove','strawberry','streetlight','string bean','submarine','suitcase','sun','swan','sweater','swing set','sword','syringe','table','teapot','teddy-bear',\n",
    "#                    'telephone','television','tennis racquet','tent','The Eiffel Tower','The Great Wall of China','The Mona Lisa','tiger','toaster','toe','toilet','tooth','toothbrush','toothpaste','tornado','tractor',\n",
    "#                    'traffic light','train','tree','triangle','trombone','truck','trumpet','t-shirt','umbrella','underwear','van','vase','violin','washing machine','watermelon','waterslide','whale','wheel','windmill',\n",
    "#                    'wine bottle','wine glass','wristwatch','yoga','zebra','zigzag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in LABELS:\n",
    "#     !wget 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{b}.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n"
     ]
    }
   ],
   "source": [
    "N_FRUITS = len(LABELS)\n",
    "FRUITS = {}\n",
    "files=[]\n",
    "for i in range(0,N_FRUITS):\n",
    "  FRUITS.update({i:LABELS[i]})\n",
    "  files.append(LABELS[i]+\".npy\")\n",
    "#FRUITS = {0: \"Apple\", 1: \"Banana\", 2: \"Grape\", 3: \"Pineapple\"}\n",
    "\n",
    "# number of samples to take in each class\n",
    "N = 5000\n",
    "\n",
    "# some other constants\n",
    "N_EPOCHS = 5\n",
    "print(N_FRUITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dir, reshaped, files,N):\n",
    "    \"Load .npy or .npz files from disk and return them as numpy arrays. \\\n",
    "    Takes in a list of filenames and returns a list of numpy arrays.\"\n",
    "\n",
    "    data = []\n",
    "    m=0\n",
    "    for file in files:\n",
    "        f = np.load(dir + file)\n",
    "        if reshaped:\n",
    "            new_f = []\n",
    "            for i in range(N):\n",
    "                x = np.reshape(f[i], (28, 28))\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = np.reshape(f[i], (28, 28, 1))\n",
    "                new_f.append(x)\n",
    "            f = new_f\n",
    "        data.append(f)\n",
    "        m+=1\n",
    "        print(\"loaded file\" , m)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = load(\"\", True, files[:170],N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('outfile2', 'ab') as fp:\n",
    "#     pickle.dump(data1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2183424\n",
      "drwxr-xr-x 14 jupyter jupyter       4096 Apr 22 18:56 tutorials\n",
      "drwxr-xr-x  5 jupyter jupyter       4096 Apr 22 18:56 src\n",
      "-rw-r--r--  1 jupyter jupyter        557 Apr 22 23:01 autoencoder1log.csv\n",
      "-rw-r--r--  1 jupyter jupyter    7137328 Apr 22 23:01 autoencoder1.check\n",
      "-rw-r--r--  1 jupyter jupyter    7137328 Apr 22 23:31 autoencoder.h5\n",
      "-rw-r--r--  1 jupyter jupyter   11370456 Apr 23 00:25 autoencoder2.check\n",
      "-rw-r--r--  1 jupyter jupyter        368 Apr 23 00:27 autoencoder2log.csv\n",
      "-rw-r--r--  1 jupyter jupyter   11370456 Apr 23 00:29 autoencoder_classification.h5\n",
      "-rw-r--r--  1 jupyter jupyter        877 Apr 23 01:24 autoencoder3log.csv\n",
      "-rw-r--r--  1 jupyter jupyter   11370456 Apr 23 01:24 autoencoder3.check\n",
      "-rw-r--r--  1 jupyter jupyter   11370456 Apr 23 01:43 classification_complete.h5\n",
      "drwxr-xr-x  5 jupyter jupyter       4096 Apr 23 04:23 CS6140-ML-Doodle-Recognition\n",
      "-rw-r--r--  1 jupyter jupyter 1436504212 Apr 23 06:11 outfile2\n",
      "-rw-r--r--  1 jupyter jupyter  739377186 Apr 23 06:12 outfile1\n",
      "-rw-r--r--  1 jupyter jupyter      62440 Apr 23 06:32 autoencoder.ipynb\n",
      "-rw-r--r--  1 jupyter jupyter      75099 Apr 23 06:33 autoencoder-with more epochs.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outfile2', 'rb') as fp:\n",
    "    mynewlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mynewlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 5000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnl=array(mynewlist)\n",
    "mnl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = load(\"\", True, files[170:],N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('outfile1', 'ab') as f:\n",
    "#     pickle.dump(data2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outfile1', 'rb') as fp:\n",
    "    mynewlist2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mynewlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 5000, 28, 28, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnl2=array(mynewlist2)\n",
    "mnl2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=mynewlist+mynewlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data=train_data.reshape(1725000,28,28,1)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn=[int(i/5000) for i in range(1725000) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: aircraft carrier)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[10], (28,28))\n",
    "#curr_lbl = y_trn[10]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(LABELS[int(10/5000)]) + \")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e0b5b5e92452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                              \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                              \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                              random_state=13)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2212\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2212\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data,\n",
    "                                                             test_size=0.2,\n",
    "                                                             random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "num_classes = 345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    #decoder\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9bf39c56cea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_img' is not defined"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [EarlyStopping(patience=1),\n",
    "                ReduceLROnPlateau(patience=5, verbose=1),\n",
    "                CSVLogger('autoencoder1log.csv'),\n",
    "                ModelCheckpoint('autoencoder1.check',\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-89c3baebcb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m autoencoder_train = autoencoder.fit(train_X, train_ground, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                    callbacks=callback)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, \n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=epochs,\n",
    "                                    verbose=1,validation_data=(valid_X, valid_ground),\n",
    "                                   callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (200,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-eca54368e5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(20)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725000\n",
      "Original label: 0\n",
      "After conversion to one-hot: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_labels=[int(i/5000) for i in range(0,1725000) ]\n",
    "print(len(train_labels))\n",
    "train_Y_one_hot = to_categorical(train_labels)\n",
    "\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_labels[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(train_data,train_Y_one_hot,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1380000, 28, 28, 1), (345000, 28, 28, 1), (1380000, 345), (345000, 345))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(den)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encode = encoder(input_img)\n",
    "full_model = Model(input_img,fc(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.96307500e-02, -2.64959073e+00, -2.95178536e-02,\n",
       "         -1.04676616e+00,  8.68936330e-02,  9.69107687e-01,\n",
       "         -3.41910064e-01, -1.04533744e+00,  2.15702150e-02,\n",
       "          9.40196663e-02, -1.34976879e-01,  2.96876907e-01,\n",
       "          5.84321916e-01, -5.39822757e-01, -4.51260544e-02,\n",
       "          5.94212353e-01, -1.09639955e+00,  5.36705196e-01,\n",
       "          1.41507089e-02, -1.67508766e-01,  7.95525908e-01,\n",
       "          3.53343487e-01, -9.92079079e-02, -8.06467533e-02,\n",
       "         -1.32826716e-02,  2.07283989e-01, -5.90708060e-03,\n",
       "          1.21571738e-02,  6.92274034e-01,  2.36996189e-01,\n",
       "          3.68026793e-01,  1.28752083e-01]],\n",
       "\n",
       "       [[-9.99432206e-01, -3.61994833e-01,  6.22246452e-02,\n",
       "         -3.17913115e-01, -1.73977047e-01,  1.88833103e-01,\n",
       "          2.58020163e-01, -3.44199419e-01, -9.90749747e-02,\n",
       "          2.56630957e-01,  6.25503361e-01,  5.67679882e-01,\n",
       "         -7.68977642e-01, -1.34592497e+00,  3.72137517e-01,\n",
       "          1.64162561e-01,  6.66346550e-02, -7.01439083e-01,\n",
       "         -1.78396851e-01,  3.19464505e-01, -5.13954997e-01,\n",
       "         -8.15203786e-01, -6.31759703e-01,  6.22437410e-02,\n",
       "          3.22678655e-01, -3.40619981e-01, -1.66492760e-01,\n",
       "         -2.85536945e-01, -9.00059402e-01, -7.59607732e-01,\n",
       "         -2.28542313e-01,  9.44569826e-01]],\n",
       "\n",
       "       [[-1.01544581e-01,  1.30516440e-01, -6.81118295e-02,\n",
       "         -1.98748857e-02,  7.27486163e-02, -1.09618104e+00,\n",
       "         -9.54233781e-02,  5.84582649e-02, -1.31516205e-03,\n",
       "         -5.18713236e-01,  2.69796968e-01,  3.53968650e-01,\n",
       "          2.82332987e-01, -3.77814323e-01, -1.46436766e-01,\n",
       "          5.88474393e-01,  1.03090310e+00,  1.35861680e-01,\n",
       "         -6.10754006e-02, -1.21785454e-01, -4.64101881e-01,\n",
       "          3.37607026e-01,  2.21407693e-02, -1.00325525e-01,\n",
       "         -3.43446136e-01,  4.46045920e-02, -6.29844069e-02,\n",
       "          3.14172983e-01,  2.27261439e-01, -2.26199031e-01,\n",
       "         -7.34486997e-01, -5.35329152e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.96307500e-02, -2.64959073e+00, -2.95178536e-02,\n",
       "         -1.04676616e+00,  8.68936330e-02,  9.69107687e-01,\n",
       "         -3.41910064e-01, -1.04533744e+00,  2.15702150e-02,\n",
       "          9.40196663e-02, -1.34976879e-01,  2.96876907e-01,\n",
       "          5.84321916e-01, -5.39822757e-01, -4.51260544e-02,\n",
       "          5.94212353e-01, -1.09639955e+00,  5.36705196e-01,\n",
       "          1.41507089e-02, -1.67508766e-01,  7.95525908e-01,\n",
       "          3.53343487e-01, -9.92079079e-02, -8.06467533e-02,\n",
       "         -1.32826716e-02,  2.07283989e-01, -5.90708060e-03,\n",
       "          1.21571738e-02,  6.92274034e-01,  2.36996189e-01,\n",
       "          3.68026793e-01,  1.28752083e-01]],\n",
       "\n",
       "       [[-9.99432206e-01, -3.61994833e-01,  6.22246452e-02,\n",
       "         -3.17913115e-01, -1.73977047e-01,  1.88833103e-01,\n",
       "          2.58020163e-01, -3.44199419e-01, -9.90749747e-02,\n",
       "          2.56630957e-01,  6.25503361e-01,  5.67679882e-01,\n",
       "         -7.68977642e-01, -1.34592497e+00,  3.72137517e-01,\n",
       "          1.64162561e-01,  6.66346550e-02, -7.01439083e-01,\n",
       "         -1.78396851e-01,  3.19464505e-01, -5.13954997e-01,\n",
       "         -8.15203786e-01, -6.31759703e-01,  6.22437410e-02,\n",
       "          3.22678655e-01, -3.40619981e-01, -1.66492760e-01,\n",
       "         -2.85536945e-01, -9.00059402e-01, -7.59607732e-01,\n",
       "         -2.28542313e-01,  9.44569826e-01]],\n",
       "\n",
       "       [[-1.01544581e-01,  1.30516440e-01, -6.81118295e-02,\n",
       "         -1.98748857e-02,  7.27486163e-02, -1.09618104e+00,\n",
       "         -9.54233781e-02,  5.84582649e-02, -1.31516205e-03,\n",
       "         -5.18713236e-01,  2.69796968e-01,  3.53968650e-01,\n",
       "          2.82332987e-01, -3.77814323e-01, -1.46436766e-01,\n",
       "          5.88474393e-01,  1.03090310e+00,  1.35861680e-01,\n",
       "         -6.10754006e-02, -1.21785454e-01, -4.64101881e-01,\n",
       "          3.37607026e-01,  2.21407693e-02, -1.00325525e-01,\n",
       "         -3.43446136e-01,  4.46045920e-02, -6.29844069e-02,\n",
       "          3.14172983e-01,  2.27261439e-01, -2.26199031e-01,\n",
       "         -7.34486997e-01, -5.35329152e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 345)               44505     \n",
      "=================================================================\n",
      "Total params: 2,825,785\n",
      "Trainable params: 1,650,265\n",
      "Non-trainable params: 1,175,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [EarlyStopping(patience=1),\n",
    "                ReduceLROnPlateau(patience=5, verbose=1),\n",
    "                CSVLogger('autoencoder2log.csv'),\n",
    "                ModelCheckpoint('autoencoder2.check',\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1380000 samples, validate on 345000 samples\n",
      "Epoch 1/10\n",
      "1380000/1380000 [==============================] - 134s 97us/step - loss: 5.3991 - acc: 0.0124 - val_loss: 5.2028 - val_acc: 0.0190\n",
      "Epoch 2/10\n",
      "1380000/1380000 [==============================] - 129s 93us/step - loss: 5.1606 - acc: 0.0194 - val_loss: 5.1362 - val_acc: 0.0177\n",
      "Epoch 3/10\n",
      "1380000/1380000 [==============================] - 127s 92us/step - loss: 5.1024 - acc: 0.0213 - val_loss: 5.0848 - val_acc: 0.0230\n",
      "Epoch 4/10\n",
      "1380000/1380000 [==============================] - 128s 93us/step - loss: 5.0761 - acc: 0.0227 - val_loss: 5.0919 - val_acc: 0.0220\n"
     ]
    }
   ],
   "source": [
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=10,verbose=1,validation_data=(valid_X, valid_label),\n",
    "                               callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save_weights('autoencoder_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [EarlyStopping(patience=5),\n",
    "                ReduceLROnPlateau(patience=5, verbose=1),\n",
    "                CSVLogger('autoencoder3log.csv'),\n",
    "                ModelCheckpoint('autoencoder3.check',\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1380000 samples, validate on 345000 samples\n",
      "Epoch 1/10\n",
      "1380000/1380000 [==============================] - 333s 242us/step - loss: 5.0151 - acc: 0.0243 - val_loss: 4.8660 - val_acc: 0.0318\n",
      "Epoch 2/10\n",
      "1380000/1380000 [==============================] - 330s 239us/step - loss: 4.7931 - acc: 0.0346 - val_loss: 4.6701 - val_acc: 0.0457\n",
      "Epoch 3/10\n",
      "1380000/1380000 [==============================] - 330s 239us/step - loss: 4.6364 - acc: 0.0471 - val_loss: 4.5549 - val_acc: 0.0527\n",
      "Epoch 4/10\n",
      "1380000/1380000 [==============================] - 329s 238us/step - loss: 4.0822 - acc: 0.1295 - val_loss: 3.5284 - val_acc: 0.2300\n",
      "Epoch 5/10\n",
      "1380000/1380000 [==============================] - 327s 237us/step - loss: 2.9711 - acc: 0.3468 - val_loss: 2.5660 - val_acc: 0.4311\n",
      "Epoch 6/10\n",
      "1380000/1380000 [==============================] - 325s 236us/step - loss: 2.3635 - acc: 0.4756 - val_loss: 2.2100 - val_acc: 0.5110\n",
      "Epoch 7/10\n",
      "1380000/1380000 [==============================] - 330s 239us/step - loss: 1.5747 - acc: 0.6306 - val_loss: 1.5917 - val_acc: 0.6259\n",
      "Epoch 10/10\n",
      "1380000/1380000 [==============================] - 332s 241us/step - loss: 1.4274 - acc: 0.6585 - val_loss: 1.4909 - val_acc: 0.6472\n"
     ]
    }
   ],
   "source": [
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=10,verbose=1,validation_data=(valid_X, valid_label),\n",
    "                               callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save_weights('classification_complete.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = classify_train.history['acc']\n",
    "val_accuracy = classify_train.history['val_acc']\n",
    "loss = classify_train.history['loss']\n",
    "val_loss = classify_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_final', 'rb') as ft:\n",
    "    testlist = pickle.load(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"Takes a list or a list of lists and returns its normalized form\"\n",
    "\n",
    "    return np.interp(data, [0, 255], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(N1, N2):\n",
    "    \"make labels from 0 to N1, each repeated N2 times\"\n",
    "    labels = []\n",
    "    for i in range(N1):\n",
    "        labels += [i] * N2\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_limit(arrays, n):\n",
    "    \"Limit elements from each array up to n elements and return a single list\"\n",
    "    new = []\n",
    "    for array in arrays:\n",
    "        i = 0\n",
    "        for item in array:\n",
    "            if i == n:\n",
    "                break\n",
    "            new.append(item)\n",
    "            i += 1\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = list(map(normalize, testlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_labels = make_labels(345, 10)\n",
    "\n",
    "\n",
    "test_Y = keras.utils.to_categorical(test_labels, 345)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = set_limit(testlist, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3450"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(array):\n",
    "    \"Visulaze a 2D array as an Image\"\n",
    "    array = np.reshape(array, (28,28))\n",
    "    img = Image.fromarray(array)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  64.17391304347827 %\n"
     ]
    }
   ],
   "source": [
    "predsTest = full_model.predict(np.array(testlist))\n",
    "# print(predsTest)\n",
    "score = 0\n",
    "for i in range(len(predsTest)):\n",
    "    #print(np.argmax(predsTest[i]))\n",
    "    if np.argmax(predsTest[i]) == test_labels[i]:\n",
    "        score += 1\n",
    "\n",
    "print(\"Accuracy: \", ((score + 0.0) / len(predsTest)) * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
